\chapter{A review of the original Heston model}
    \section{Basic facts}
        We shall use the following resources in this chapter: \cite{Heston1993} and \cite{Gatheral2012}.
        Assume that the spot asset's price $S$ at time $t$ follows the diffusion \eqref{Heston:price} -- \eqref{Heston:variance}:
        \begin{align}
            dS(t) & = \mu S(t)dt + \sqrt{v(t)} S(t) dZ_1(t), \label{Heston:price}\\
            dv(t) & = \left(\delta^2 - 2\beta v(t)\right) dt + 2\delta \sqrt{v(t)} dZ_2(t), \label{Heston:variance}
        \end{align}
        where $Z_1$, $Z_2$ are the correlated Wiener processes with $dZ_1dZ_2 = \rho dt$.
    \section{PDEs}
    \section{A closed-form solution for the European call option}
\chapter{A review of the Monte-Carlo methods for diffusions}
    \section{Randomness in Probability Theory}
        A. N. Kolmogorov in <<On Logical Foundations of Probability Theory>>: 
        
        \textit {In everyday language we call random these phenomena where we cannot find a regularity allowing us to predict precisely their results. Generally speaking there is no ground to believe that a random phenomenon should possess any definite probability. Therefore, we should have distinguished between randomness proper
        (as absence of any regularity) and stochastic randomness (which is the subject of the probability theory).
        Since randomness is defined as absence of regularity, we should
        primarily specify the concept of regularity. The natural means of such a specification is the theory of algorithms and recursive functions...}

        Check out the \href{https://youtu.be/qKVoFqp1DzA}{lecture by A. N. Shiryaev} for more details.

    \section{Laws of Large Numbers and Central Limit Theorem}
        \begin{theorem}[Khinchin]
            Let $X_1, X_2, \dots, X_n$ be a sequence of independent and identically distributed random variables with $\E X_i = \mu$. Then
            \begin{equation}
                \plim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n X_i = \mu.
            \end{equation}
        \end{theorem}
        \begin{theorem}[Kolmogorov]
            Let $X_1, X_2, \dots, X_n$ be a sequence of independent and identically distributed random variables. Then $\exists \E X_i = \mu$, if and only if
            \begin{equation}
                \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n X_i \overset{\text{a.s.}}{=} \mu.
            \end{equation}
        \end{theorem}

        \begin{theorem}[Lindeberg-L\'evy]
            Let $X_1, \dots, X_n$ be a sequence of i.i.d. random variables with $\mathbb{E}[X_i] = \mu$ and $\var\left[X_i\right] = \sigma^2$. 
            Then as $n$ approaches infinity, the random variables $\sqrt{n}(\bar{X}_n - \mu)$ converge in law to a normal distribution $\cN(0, \sigma^2)$, i.e.
            \begin{equation}
                \sqrt{n}\left(\bar{X}_n - \mu\right) \xrightarrow{d} \cN\left(0,\sigma^2\right).
            \end{equation}
        \end{theorem}

        Law of large numbers is an informal corollary of the central limit theorem.



    \section{The Statistical Foundations of the Monte-Carlo Methods}
        \begin{lemma}
            Let $X_1, X_2, \dots, X_n$ be a series of independent and identically distributed random variables, and $h: \mathbb{R} \to \mathbb{R}$ be a borel function. Then $h(X_1), h(X_2), \dots, h(X_n)$ is a series of independent and identically distributed random variables.
        \end{lemma}
        Thus, we could write an unbiased consistent estimator of $\E \left[h(X)\right]$ as follows:
        \begin{equation}
            \widehat{\E \left[h(X)\right]} = \frac{1}{n} \sum_{i=1}^n h(X_i).
        \end{equation}
        \begin{definition}
            Monte Carlo simulation is a set of techniques that use pseudorandom number generators to solve problems that might be too complicated to be solved analytically. It is based on the central limit theorem.
        \end{definition}
        Asymptotic confidence interval for $\hat{\mu} = \widehat{\E\left[X\right]}$ at the confidence level $\alpha$:
        \begin{equation}
            \mu \in \left(\hat{\mu} - z_{\alpha/2} \sqrt{\frac{\sigma^2}{n}}, \hat{\mu} + z_{\alpha/2} \sqrt{\frac{\sigma^2}{n}}\right).
        \end{equation}
        That means that the estimation error is equal to $2z_{\alpha/2} \sqrt{\frac{\sigma^2}{n}}$.


    \section{General Monte-Carlo Methods for Gaussian Diffusions}

    \section{The Main Three Methods}
        \subsection{Euler-Maruyama}
            \subsubsection{Forward Euler Scheme for ODEs}
                Suppose that we have an ODE of the form
                \begin{equation}
                    dX(t) = f(X(t), t)dt, \quad X(0) = X_0. \label{eq:ode}
                \end{equation}
                Then it could be numerically solved by the following finite difference scheme:
                \begin{equation}
                    X_{n+1} = X_n + f(t_n, X_n)h_n, \label{Euler:ODE}
                \end{equation}
                where $t_n = \sum_{k=1}^n h_n, t_0 = 0$ is a grid. 

            \subsubsection{Backward Euler Scheme for ODEs}
                Suppose that we have an ODE of the form
                \begin{equation}
                    dX(t) = f(X(t), t)dt, \quad X(0) = X_0. \label{eq:ode}
                \end{equation}
                Then it could be numerically solved by the following finite difference scheme:
                \begin{equation}
                    X_{n+1} = X_n + f(t_{n+1}, X_{n+1})h_n, \label{Backward:Euler:ODE}
                \end{equation}
                where $t_n = \sum_{k=1}^n h_n, t_0 = 0$ is a grid.

            \subsubsection{Euler-Maruyama Scheme for SDEs}
                Suppose we have a diffusion of the form 
                \begin{equation*}
                    dX(t) = f(X(t), t)dt + \sigma(X(t), t)dW(t), \quad X_0 = X_0.
                \end{equation*}
                Then it could be numerically solved by the following finite difference scheme:
                \begin{equation}
                    X_{n+1} = X_n + f(t_n, X_n)h_n + \sigma(t_n, X_n) \sqrt{h_n} Z_n, \label{Euler:SDE}
                \end{equation}
                where $(Z_n)_{n=1, 2, \dots}$ is a sample of standard normal random variables, and $t_n = \sum_{k=1}^n h_n, t_0 = 0$ is a grid.
                The same method could be generalized for the two-factor Gaussian diffusions. Further we assume
                that $(t_i)_{i = 0, 1, \dots}$ is a uniform grid with $t_i = ih$.

                \begin{definition}
                    Let $\hat X^n(t)$ be a piecewise mesh approximation of an SDE solution $X(t)$ (we assume that there exists a unique strong solution). 
                    Then a scheme is said to have a strong convergence of order $p$ if 
                    \begin{equation}
                        \E\left[\left|\hat X^n(T) - X(T)\right|\right] \leq Ch^p, \quad n \to \infty.
                    \end{equation}
                    A scheme is said to have a weak convergence of order $p$ if for any polynomial $f: \R \to \R$ we have
                    \begin{equation}
                        \left|\E\left[f(\hat X^n(T))\right] - \E\left[f(X(T))\right]\right| \leq Ch^p, \quad n \to \infty.
                    \end{equation}
                \end{definition}

                \begin{theorem}
                    Under some technical assumptions the Euler-Maruyama scheme \eqref{Euler:SDE} has a strong convergence of order $1/2$ and a weak convergence of order $1$.
                \end{theorem}
            
                Since our goal is to approximate $\E\left[h(X)\right]$ with a given accuracy and the least possible number of simulations, we need to compare the weak convergence rate between the methods.
                
                

\chapter{The Three Methods of Simulation of the Heston Model}
    \section{Euler Scheme}
        Suppose we have the Heston model \eqref{Heston:price} -- \eqref{Heston:variance}. Then it could be numerically solved by the following finite difference scheme:
        \begin{align}
            S_{n+1} & = S_n + \mu S_n h_n + \sqrt{v_n} S_n \sqrt{h_n} Z_{1,n}, \label{Euler:Heston:price}\\
            v_{n+1} & = v_n + \left(\delta^2 - 2\beta v_n\right) h_n + \sigma \sqrt{v_n} \sqrt{h_n} Z_{2,n}, \label{Euler:Heston:variance}
        \end{align}
        where $(Z_{1,n})_{n=1, 2, \dots}$ and $(Z_{2,n})_{n=1, 2, \dots}$ are $\rho$-correlated samples of standard normal random variables, and $t_n = \sum_{k=1}^n h_n$ is a mesh grid.
        But we have a problem: during simulation of the Heston model using Euler method $S_{t_n}$ and $v_{t_n}$ could be negative. How do we deal with this inconvenience?
        Let us introduce the log-prices
        \begin{equation}
            X(t) := \log\frac{S(t)}{S(0)}.
        \end{equation}
        We take the positive part of the variance:
        \begin{align}
            X_{n+1} & = X_n + (\mu - 0.5 v_n^+)h_n + \sqrt{v_n^+} X_n \sqrt{h_n} Z_{1,n}, \label{Euler:Heston:price:posmod}\\
            v_{n+1} & = v_n + \left(\delta^2 - 2\beta v_n^+\right) h_n + \sigma \sqrt{v_n^+} \sqrt{h_n} Z_{2,n}, \label{Euler:Heston:variance:posmod}
        \end{align}
        and then we take the exponential of the log-prices:
        \begin{equation}
            S_{n} = S_0 e^{X_{n}}.
        \end{equation}
        
        However, the scheme is not accurate, since we ignore the $dZ_idZ_j$ terms in the It\^o-Taylor series approximation.

    \section{Broadie-Kaya Scheme}

    \section{Andersen Scheme}

